{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubychiu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"./Data/train_2016_v2.csv\")    # load dataset\n",
    "properties = pd.read_csv(\"./Data/properties_2016.csv\")\n",
    "test_df = pd.read_csv(\"./Data/sample_submission.csv\")\n",
    "test_df = test_df.rename(columns={'ParcelId': 'parcelid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.merge(properties, how = 'left', on = 'parcelid') # get a complete dataframe\n",
    "test_df = test_df.merge(properties, on='parcelid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4638819999999963\n",
      "-0.3425\n"
     ]
    }
   ],
   "source": [
    "# get outlier of logerror\n",
    "ulimit = np.percentile(train_df.logerror.values, 99)  \n",
    "print(ulimit)\n",
    "llimit = np.percentile(train_df.logerror.values, 1)\n",
    "print(llimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train data and test data without outlier\n",
    "# don't change the code about test data\n",
    "train_df = train_df[train_df.logerror > -0.3425]\n",
    "train_df = train_df[train_df.logerror < 0.4639]\n",
    "do_not_include = ['parcelid', 'logerror', 'transactiondate']\n",
    "feature_names = [f for f in train_df.columns if f not in do_not_include]\n",
    "#X_train = train_df.drop(['parcelid', 'logerror', 'transactiondate'] ,axis = 1)\n",
    "X_train = train_df[feature_names].copy()\n",
    "y_train = train_df.logerror\n",
    "test_df = test_df[feature_names].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get training data and validation data(we don't need do this when we want to submit to kaggle, just use all data to train)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size =0.8, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hashottuborspa', 'propertycountylandusecode', 'propertyzoningdesc', 'fireplaceflag', 'taxdelinquencyflag']\n"
     ]
    }
   ],
   "source": [
    "# get the data index which is categorical \n",
    "\n",
    "s = (X_train.dtypes =='object')\n",
    "object_cols = list(s[s].index)\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# use labelencoder to encoder X_train and test data\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "test = test_df.copy()\n",
    "for col in label_X_train.columns:\n",
    "    label_X_train[col] = label_X_train[col].fillna(-1)\n",
    "    test[col] = test[col].fillna(-1)\n",
    "    if label_X_train[col].dtype =='object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(label_X_train[col].values))\n",
    "        label_X_train[col] = lbl.transform(list(label_X_train[col].values))\n",
    "    if  test[col].dtype == 'object':\n",
    "        lbl.fit(list(test[col].values))\n",
    "        test[col] = lbl.transform(list(test[col].values))\n",
    "x_test = test.copy()\n",
    "\n",
    "#use labelencoder to encoder X_vaid, this part can be deleted\n",
    "for col in label_X_valid.columns:\n",
    "    label_X_valid[col] = label_X_valid[col].fillna(-1)\n",
    "    if label_X_valid[col].dtype =='object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(label_X_valid[col].values))\n",
    "        label_X_valid[col] = lbl.transform(list(label_X_valid[col].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70772, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70772,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(label_X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:09:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rubychiu/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=5,\n",
       "             gamma=0, importance_type='gain', learning_rate=0.05,\n",
       "             max_delta_step=0, max_depth=7, min_child_weight=1, missing=None,\n",
       "             n_estimators=500, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost model 1\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "XGB_model_1 = XGBRegressor(n_estimators = 500, early_stopping_rounds = 5, learning_rate = 0.05, max_depth = 7, objective='reg:linear')\n",
    "XGB_model_1.fit(label_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# get kaggle verification predictioin result\n",
    "XGB_predictions_1 = XGB_model_1.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03455275, -0.03566307,  0.03666675, ...,  0.2911566 ,\n",
       "        0.2911566 ,  0.2911566 ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_predictions_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(XGB_predictions_1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import xgboost\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12,18))\n",
    "# xgboost.plot_importance(XGB_model_1, max_num_features=50, height=0.8, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_XGB_1 = mean_absolute_error(y_valid, XGB_predictions_1)\n",
    "# print(mae_XGB_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get feature which importance score is higher than 600 from the picture\n",
    "# #selected_features = ['taxamount', 'calculatedfinishedsquarefeet', 'structuretaxvaluedollarcnt', 'longitude',\n",
    "#                                      'finishedsquarefeet12', 'latitude','regionidzip','taxvaluedollarcnt','lotsizesquarefeet',\n",
    "#                                     'landtaxvaluedollarcnt','rawcensustractandblock','yearbuilt','propertyzoningdesc'\n",
    "#                                     ,'taxdelinquencyyear','bathroomcnt','bedroomcnt','regionidneighborhood' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing csv ...\n"
     ]
    }
   ],
   "source": [
    "# writing csv result file\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = XGB_predictions_1 \n",
    "\n",
    "print('Writing csv ...')\n",
    "sub.to_csv('XGB_submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.3,max_iter=10000)\n",
    "lasso.fit(label_X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_predictions = lasso.predict(test)\n",
    "#test\n",
    "#MAE_value = mean_absolute_error(lasso_predictions, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing csv ...\n"
     ]
    }
   ],
   "source": [
    "# writing csv result file\n",
    "sub = pd.read_csv('../input/Data/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = lasso_predictions\n",
    "print('Writing csv ...')\n",
    "sub.to_csv('Lasso_submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
